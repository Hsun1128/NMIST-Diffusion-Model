<p align="center">
  <a href="#">
    <img src="docs/images/demo.gif" alt="MNIST Diffusion Demo" width="520"/>
  </a>
</p>

<h1 align="center">âœ¨ DDPM MNIST</h1>

<p align="center">
  <a href="https://pytorch.org/"><img src="https://img.shields.io/badge/PyTorch-2.3-orange?logo=pytorch" alt="PyTorch"></a>
  <a href="./requirements.txt"><img src="https://img.shields.io/badge/Deps-ready-green" alt="Dependencies"></a>
  <a href="./dockerfile"><img src="https://img.shields.io/badge/Docker-CUDA%2012.1-blue?logo=docker" alt="Docker"></a>
  <a href="https://github.com/Hsun1128/NMIST-Diffusion-Model"><img src="https://img.shields.io/badge/GitHub-Source-blue?logo=github" alt="GitHub"></a>
</p>

æœ¬å°ˆæ¡ˆå¾é ­è¨“ç·´ Denoising Diffusion Probabilistic Model (DDPM) æ–¼ MNIST PNG å½±åƒï¼Œæ¶µè“‹è³‡æ–™ç®¡ç·šã€ç²¾ç°¡ç‰ˆ U-Netã€æ“´æ•£éç¨‹å¯¦ä½œã€è¨“ç·´/ç”Ÿæˆè…³æœ¬èˆ‡è¦–è¦ºåŒ–å·¥å…·ï¼Œå¿«é€Ÿé‡ç¾èˆ‡å»¶ä¼¸ç›¸é—œæ‡‰ç”¨ã€‚

## ğŸ“ˆ æˆæœæ‘˜è¦

- FID â‰ˆ **7.85**ï¼ˆ`trained_model/mnist-ddpm-baseline/checkpoints/best.pt`ï¼Œç”Ÿæˆ 10,000 å¼µå½±åƒèˆ‡ `mnist/` åƒè€ƒé›†æ¯”è¼ƒï¼‰
- ç¯„ä¾‹ç”Ÿæˆæ¨£æœ¬ï¼š`trained_model/mnist-ddpm-baseline/sample_step_*.png`
- æ“´æ•£éç¨‹è¦–è¦ºåŒ–ï¼š`trained_model/mnist-ddpm-baseline/diffusion_progress.png`

<p align="center">
  <a href="docs/images/diffusion_progress.png">
    <img src="docs/images/diffusion_progress.png" alt="Diffusion Progress" width="520"/>
  </a>
</p>

> åœ–ç¤ºå±•ç¤º 8 å€‹æ¡æ¨£éšæ®µçš„é‚„åŸéç¨‹ï¼šè‡ªç´”å™ªè²é€æ­¥ç”Ÿæˆæ¸…æ™°çš„æ‰‹å¯«æ•¸å­—ã€‚

> [!TIP]
> æƒ³å¿«é€Ÿé©—è­‰è¨“ç·´æ•ˆæœï¼Ÿç›´æ¥åŸ·è¡Œ `bash run_training.sh` å¾Œæª¢è¦– `trained_model/<run>/diffusion_progress.png` èˆ‡ `train_log.csv`ï¼Œå³å¯ç¢ºèªæ”¶æ–‚èˆ‡ç”Ÿæˆå“è³ªã€‚

> [!WARNING]
> ç”±æ–¼å°ˆæ¡ˆæœƒæŒçºŒå¾ `mnist/` è®€å– PNGï¼Œè«‹ç¢ºä¿è©²è³‡æ–™å¤¾åªåŒ…å« MNIST æä¾›çš„åˆæ³•å½±åƒï¼Œä¸¦é¿å…åœ¨å…¬é–‹ç’°å¢ƒæš´éœ²å€‹äººè³‡æ–™æˆ–éæˆæ¬Šå½±åƒã€‚

## ğŸš€ å°ˆæ¡ˆèªªæ˜

- **æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼š`src/` ä»¥è³‡æ–™ã€æ“´æ•£ã€æ¨¡å‹ã€è¨“ç·´ã€ç”Ÿæˆã€å¯è¦–åŒ–æ‹†åˆ†ï¼Œæ–¹ä¾¿æ›¿æ›æˆ–æ“´å……ã€‚
- **é‡ç¾æ€§**ï¼šçµ±ä¸€ä½¿ç”¨ `mnist/` è³‡æ–™å¤¾èˆ‡ `set_seed`ï¼Œå³ä½¿åœ¨ Docker/Compose ç’°å¢ƒä¹Ÿèƒ½ç©©å®šé‡ç¾ã€‚
- **è¦–è¦ºåŒ–å®Œæ•´**ï¼šæä¾› demo GIFã€è¨“ç·´éç¨‹æ¡æ¨£ã€æ“´æ•£è»Œè·¡èˆ‡ FID è¨ˆç®—æµç¨‹ã€‚
- **é«˜æ•ˆç‡ç”Ÿæˆ**ï¼š`run_generate.sh` æ”¯æ´å¤§æ‰¹é‡ç”¢åœ–ï¼ˆé è¨­ 10kï¼‰ä¸¦å…è¨±è‡ªè¨‚æ‰¹æ¬¡å¤§å°é¿å… OOMã€‚

## å°ˆæ¡ˆçµæ§‹ï¼ˆTree Viewï¼‰

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ dockerfile                 # CUDA 12.1 + PyTorch 2.3.1/cu121 ç’°å¢ƒ
â”œâ”€â”€ docker-compose.yaml        # æ–¹ä¾¿å•Ÿå‹•å®¹å™¨
â”œâ”€â”€ run_training.sh            # åŸºç·šè¨“ç·´è…³æœ¬ï¼ˆ50 epochs, base_channels=128ï¼‰
â”œâ”€â”€ run_generate.sh            # ç”Ÿæˆ 10,000 å¼µ 28Ã—28 RGB PNG
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ images/                # README ç¤ºæ„åœ–ï¼ˆdemo.gif, diffusion_progress.pngï¼‰
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py                # MNIST PNG è³‡æ–™é›†èˆ‡å¯é‡ç¾åˆ‡åˆ†
â”‚   â”œâ”€â”€ diffusion.py           # DDPM q/p éç¨‹èˆ‡æ¡æ¨£ API
â”‚   â”œâ”€â”€ model.py               # ç²¾ç°¡ U-Netï¼ˆæ™‚é–“åµŒå…¥ + æ®˜å·® + ä¸Šä¸‹æ¡æ¨£ï¼‰
â”‚   â”œâ”€â”€ trainer.py             # æ ¸å¿ƒè¨“ç·´è¿´åœˆï¼ˆloggingã€samplingã€checkpointï¼‰
â”‚   â”œâ”€â”€ logger.py              # CSV logger
â”‚   â”œâ”€â”€ train_diffusion.py     # è¨“ç·´å…¥å£é»
â”‚   â”œâ”€â”€ generate_images.py     # ä¾ checkpoint ç”Ÿæˆå¤§é‡ PNG
â”‚   â””â”€â”€ visualize_diffusion.py # ç”¢ç”Ÿæ“´æ•£è»Œè·¡ snapshot åœ–
â”œâ”€â”€ mnist/                     # MNISTçš„ PNG è³‡æ–™ï¼ˆé è¨­ --data-dir mnistï¼‰
â”œâ”€â”€ trained_model/             # ç¯„ä¾‹è¨“ç·´è¼¸å‡ºï¼ˆcheckpointsã€æ¨£æœ¬ã€loss æ›²ç·šï¼‰
â””â”€â”€ generated/                 # é è¨­ç”Ÿæˆå½±åƒè¼¸å‡ºç›®éŒ„
```

## æ¨¡å‹èˆ‡æ–¹æ³•æ¦‚è¿°

1. **Forward Diffusion**[ï¼ˆHo et al., 2020ï¼‰](https://arxiv.org/abs/2006.11239)ï¼šä¾ç·šæ€§ Î² æ’ç¨‹æ³¨å…¥å™ªè²ï¼Œå½¢æˆ `x_t = âˆšÎ±Ì„_t x_0 + âˆš(1-Î±Ì„_t)Ïµ`ã€‚
2. **ç²¾ç°¡ U-Net**ï¼ˆåƒè€ƒ DDPM åŸè«–æ–‡èˆ‡ç¤¾ç¾¤å¸¸ç”¨ U-Net å¯¦ä½œï¼‰ï¼š
   - Sinusoidal timestep embedding â†’ MLP â†’ FiLM å¼èª¿æ•´ã€‚
   - DownBlock Ã—3 æ“·å–å¤šå°ºåº¦ç‰¹å¾µï¼Œä¿ç•™ skip connectionsã€‚
   - Bottleneck é›™æ®˜å·®å¼·åŒ–è¡¨å¾µèƒ½åŠ›ã€‚
   - UpBlock Ã—3 é‡å»ºå½±åƒä¸¦è¼¸å‡ºå™ªè²ä¼°è¨ˆã€‚
3. **Reverse Sampling**[ï¼ˆHo et al., 2020](https://arxiv.org/abs/2006.11239)ï¼›[Nichol & Dhariwal, 2021ï¼‰](https://arxiv.org/abs/2102.09672)ï¼š`DiffusionProcess` ä»¥ DDPM å…¬å¼é€æ­¥å»å™ªï¼Œæä¾› `sample()`/`p_sample()` èˆ‡ snapshot å·¥å…·ã€‚

æ­¤æ¶æ§‹ä¿ç•™ DDPM æ ¸å¿ƒæµç¨‹ï¼Œä¸¦é‡å° 28Ã—28 MNIST èª¿æ•´é€šé“èˆ‡æ¡æ¨£ç­–ç•¥ä»¥é™ä½è³‡æºéœ€æ±‚ã€‚

### æ¨¡å‹æ¶æ§‹ç¤ºæ„

```mermaid
flowchart TD
    A([Input<br/>3Ã—28Ã—28]) --> B[[Initial Conv<br/>3â†’64<br/>28Ã—28]]
    B --> C1[[DownBlock #1<br/>64â†’64<br/>28â†’14 px]]
    C1 -->|"Skip S1"| S1[( )]
    C1 --> C2[[DownBlock #2<br/>64â†’128<br/>14â†’7 px]]
    C2 -->|"Skip S2"| S2[( )]
    C2 --> C3[[DownBlock #3<br/>128â†’256<br/>7Ã—7]]
    C3 -->|"Skip S3"| S3[( )]
    C3 --> D[[Mid Residual Blocks<br/>256 @ 7Ã—7]]
    D --> U1[[UpBlock #1<br/>concat @ 7Ã—7 â†’ upsample 14Ã—14]]
    S3 --> U1
    U1 --> U2[[UpBlock #2<br/>concat @ 14Ã—14 â†’ upsample 28Ã—28]]
    S2 --> U2
    U2 --> U3[[UpBlock #3<br/>concat @ 28Ã—28<br/>no extra upsample]]
    S1 --> U3
    U3 --> E[[GroupNorm + SiLU + Conv<br/>64â†’3<br/>28Ã—28]]
    E --> F([Predicted Noise<br/>3Ã—28Ã—28])
```

æ¯å€‹ Down/Up Block çš†åŒ…å«å…©å±¤ `ResidualBlock`ï¼Œä¸¦ç”±æ™‚é–“åµŒå…¥æä¾› FiLM å¼èª¿åˆ¶ï¼›UpBlock æœƒåœ¨æ‹¼æ¥ skip ä¹‹å‰ä½¿ç”¨ bilinear interpolation ä»¥å°é½Šç©ºé–“å°ºå¯¸ã€‚

## ğŸ“¦ å®‰è£æŒ‡å¼•

### æœ¬æ©Ÿå®‰è£ï¼ˆPython 3.10, ä½¿ç”¨ Condaï¼‰

```bash
conda create -n mnist-ddpm python=3.10 -y
conda activate mnist-ddpm
pip install --upgrade pip
pip install -r requirements.txt
```


è³‡æ–™é›†æº–å‚™ï¼š

```bash
# MNIST data ç”± NTU TAICA CVPDL èª²ç¨‹æä¾›ï¼Œåƒ…ä½¿ç”¨ MNIST Training set: 60,000 handwritten digits
wget -O mnist.zip "https://drive.usercontent.google.com/download?id=1xVCJD6M6sE-tZJYxenLzvuEkSiYXig_F&export=download&authuser=0&confirm=t"
unzip mnist.zip -d mnist
ls mnist | head
```

`src/data.py` æœƒç›´æ¥è®€å– `mnist/` ç›®éŒ„ï¼Œä¸¦æŠŠç°éšåœ–è½‰ç‚º RGBã€æ­£è¦åŒ–åˆ° [-1, 1]ã€‚

### ğŸ³ Docker ç’°å¢ƒ

å°ˆæ¡ˆéš¨é™„ `dockerfile` èˆ‡ `docker-compose.yaml`ã€‚è‹¥åå¥½ä¸€æ¬¡å»ºç½®ä¸¦é‡è¤‡ä½¿ç”¨å®¹å™¨ï¼Œå»ºè­°é€é Composeï¼š

```bash
# ç¬¬ä¸€æ¬¡å»ºç½®
docker compose build mnist

# é€²å…¥äº’å‹•å¼ç’°å¢ƒï¼ˆGPUã€è‡ªå‹•æ›è¼‰ç›®å‰è³‡æ–™å¤¾åˆ° /appï¼‰
docker compose run --rm mnist bash
```

ä¸Šè¿°è¨­å®šæœƒï¼š

- ä½¿ç”¨ `network_mode: host` èˆ‡ `/dev/shm` å…±äº«è¨˜æ†¶é«”ï¼Œé¿å… dataloader å› é è¨­å…±äº«è¨˜æ†¶é«”ä¸è¶³è€Œå¤±æ•—ã€‚
- å•Ÿç”¨ `NVIDIA_VISIBLE_DEVICES=all` åŠ `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True`ï¼Œä»¥å……åˆ†åˆ©ç”¨å¤š GPU ä¸¦æ”¹å–„ CUDA è¨˜æ†¶é«”åˆ†æ®µé…ç½®ã€‚

è‹¥åƒ…éœ€ä¸€æ¬¡æ€§åŸ·è¡Œï¼Œä¹Ÿå¯ä½¿ç”¨å‚³çµ± `docker build`ï¼`docker run`ï¼Œå…©è€…ç’°å¢ƒä¸€è‡´ã€‚

## âš¡ï¸ è¨“ç·´æµç¨‹

### æœ¬æ©Ÿè¨“ç·´

```bash
bash run_training.sh
```

æˆ–è‡ªå®šç¾©åƒæ•¸ï¼š

```bash
python src/train_diffusion.py \
  --data-dir mnist \
  --batch-size 64 \
  --epochs 50 \
  --lr 2e-4 \
  --base-channels 128 \
  --image-size 28 \
  --timesteps 1000 \
  --beta-start 1e-4 \
  --beta-end 0.02 \
  --sample-every 2000 \
  --checkpoint-every 1000 \
  --log-every 50 \
  --eval-every 1 \
  --eval-batches 50 \
  --checkpoint-epoch-every 5 \
  --output-dir trained_model \
  --run-name mnist-ddpm-baseline \
  --seed 3407
```

### Docker è¨“ç·´

åœ¨ Compose ä¸­åŸ·è¡ŒåŒæ¨£è…³æœ¬å³å¯ï¼š

```bash
docker compose run --rm mnist bash run_training.sh
```

### è¨“ç·´è¼¸å‡º

```
trained_model/mnist-ddpm-baseline/
â”œâ”€â”€ checkpoints/         # ckpt_*.pt + best.pt
â”œâ”€â”€ sample_step_*.png    # å®šæœŸç”Ÿæˆåœ–
â”œâ”€â”€ train_log.csv        # step/epoch/loss/lr è¨˜éŒ„
â”œâ”€â”€ train_log.png        # train vs eval loss æ›²ç·š
â””â”€â”€ diffusion_progress.png
```

### åƒæ•¸èªªæ˜

- `--train-split`ï¼šé è¨­ 0.9ï¼Œé€éå›ºå®šç¨®å­ç¢ºä¿åŠƒåˆ†ä¸€è‡´ã€‚
- `--sample-every`ï¼šæ§åˆ¶è¨“ç·´ä¸­å¯è¦–åŒ–é »ç‡ï¼Œå€¼è¶Šå°è¶Šå¸¸ç”Ÿæˆæ¨£æœ¬ã€‚
- `--checkpoint-epoch-every`ï¼šé™¤æ­¥æ•¸ checkpoint å¤–ï¼Œé¡å¤–ä¿ç•™ epoch ç²’åº¦æª”æ¡ˆä»¥åˆ©å›æº¯ã€‚

## å½±åƒç”Ÿæˆ

### æœ¬æ©Ÿç”Ÿæˆ

```bash
bash run_generate.sh [checkpoint_path] [output_dir]
```

é è¨­å€¼ï¼š`checkpoint = trained_model/mnist-ddpm-baseline/checkpoints/best.pt`ã€`output_dir = generated/`ã€è¼¸å‡º 10,000 å¼µ `00001.png` è‡³ `10000.png`ã€‚

å®¢è£½åŒ–ç¯„ä¾‹ï¼š

```bash
python src/generate_images.py \
  --checkpoint trained_model/mnist-ddpm-baseline/checkpoints/best.pt \
  --output-dir generated \
  --num-images 10000 \
  --batch-size 64 \
  --model-image-size 28 \
  --output-size 28
```

### Docker ç”Ÿæˆ

```bash
docker compose run --rm mnist \
  bash run_generate.sh trained_model/mnist-ddpm-baseline/checkpoints/best.pt generated
```

## æ“´æ•£éç¨‹å¯è¦–åŒ–

```bash
python src/visualize_diffusion.py \
  --run-name mnist-ddpm-baseline \
  --output-root trained_model \
  --segments 7 \
  --batch-size 8
```

æˆ–æŒ‡å®šè‡ªè¨‚ checkpointï¼š

```bash
python src/visualize_diffusion.py \
  --checkpoint trained_model/mnist-ddpm-baseline/checkpoints/best.pt \
  --output-path trained_model/mnist-ddpm-baseline/diffusion_progress.png
```

## ç”Ÿæˆå“è³ªè©•ä¼°ï¼ˆFIDï¼‰

ä»¥ `pytorch-fid` æ¯”è¼ƒç”Ÿæˆæ¨£æœ¬èˆ‡çœŸå¯¦ MNIST PNGï¼š

```bash
python -m pytorch_fid \
  generated/path/to/images \
  mnist/path/to/reference
```

è‹¥æ²¿ç”¨é è¨­è³‡æ–™å¤¾ï¼Œå‘½ä»¤å¯ç°¡åŒ–ç‚ºï¼š

```bash
python -m pytorch_fid generated mnist
```

è«‹ç¢ºä¿å…©è³‡æ–™å¤¾çš†å«ç›¸åŒè§£æåº¦ï¼ˆ28Ã—28ï¼‰èˆ‡é€šé“ï¼ˆRGBï¼‰çš„å¤§é‡ PNGã€‚è‹¥ä½¿ç”¨ `trained_model/mnist-ddpm-baseline/checkpoints/best.pt` ç”Ÿæˆ 10,000 å¼µå½±åƒèˆ‡ `mnist/` åƒè€ƒè³‡æ–™æ¯”è¼ƒï¼Œå¯å¾—åˆ° **FID â‰ˆ 7.85**ã€‚

## é€²éšè¨­å®šèˆ‡å»ºè­°

- **æ¨¡å‹å®¹é‡**ï¼šèª¿æ•´ `--base-channels` ä»¥å¹³è¡¡å“è³ªèˆ‡è¨˜æ†¶é«”éœ€æ±‚ï¼Œ`time_dim` æœƒè‡ªå‹•å°æ‡‰ã€‚
- **æ¡æ¨£æ•ˆç‡**ï¼š`run_generate.sh` é è¨­ `--batch-size 4080`ï¼Œè‹¥ GPU è¨˜æ†¶é«”ä¸è¶³å¯é™ä½æ­¤å€¼ã€‚
- **é‡ç¾æ€§**ï¼š`trainer.set_seed` åŒæ­¥è¨­å®š Python/random/Torch/CUDA çš„éš¨æ©Ÿç¨®å­ã€‚
- **è©•ä¼°å»¶ä¼¸**ï¼šå¯æ­é… `pytorch-fid`ã€`torchmetrics` ç­‰å·¥å…·ç´å…¥æ›´å¤šæŒ‡æ¨™ï¼ˆISã€precision/recallï¼‰ã€‚

## åƒè€ƒè³‡æ–™

- Ho, Jonathan, Ajay Jain, and Pieter Abbeel. â€œDenoising Diffusion Probabilistic Models.â€ *Advances in Neural Information Processing Systems* 33 (2020). [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)
- Nichol, Alex, and Prafulla Dhariwal. â€œImproved Denoising Diffusion Probabilistic Models.â€ *ICML* (2021). [arXiv:2102.09672](https://arxiv.org/abs/2102.09672)
- PyTorch å®˜æ–¹æ–‡ä»¶ â€” [https://pytorch.org/docs/](https://pytorch.org/docs/)
- torchvision å®˜æ–¹æ–‡ä»¶ â€” [https://pytorch.org/vision/stable/index.html](https://pytorch.org/vision/stable/index.html)
- pytorch-fid GitHub å°ˆæ¡ˆ â€” [https://github.com/mseitzer/pytorch-fid](https://github.com/mseitzer/pytorch-fid)
- åŸå§‹ DDPM MNIST åƒè€ƒå¯¦ä½œï¼ˆGitHub ç¯„ä¾‹ï¼‰ â€” [https://github.com/lucidrains/denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch)

---

å¦‚éœ€æ“´å……æœ¬å°ˆæ¡ˆï¼ˆè‡ªå®šç¾©è³‡æ–™é›†ã€ä¸åŒå½±åƒå°ºå¯¸æˆ–æ¢ä»¶å¼ç”Ÿæˆï¼‰ï¼Œè«‹å…ˆèª¿æ•´ `MNISTImageFolder` çš„å‰è™•ç†èˆ‡ `UNet` çš„é€šé“/æ¡æ¨£æ·±åº¦ï¼Œä¸¦åŒæ­¥ä¿®æ”¹è¨“ç·´èˆ‡ç”Ÿæˆè…³æœ¬ä¸­çš„ `--image-size`ã€`--base-channels` ç­‰åƒæ•¸ï¼Œä»¥ç¶­æŒæ“´æ•£éç¨‹ç©©å®šæ€§ã€‚
